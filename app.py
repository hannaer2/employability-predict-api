from flask import Flask, request, jsonify
import pandas as pd
import joblib
import numpy as np
from flask_cors import CORS
import warnings
import os
import sys
import subprocess
warnings.filterwarnings('ignore')

# Enhanced library diagnostics
def check_system_libraries():
    """Check for required system libraries"""
    libraries = ['libgomp.so.1', 'libgfortran.so.5', 'libstdc++.so.6']
    missing = []
    
    for lib in libraries:
        try:
            result = subprocess.run(['ldconfig', '-p'], capture_output=True, text=True)
            if lib not in result.stdout:
                missing.append(lib)
        except:
            missing.append(lib)
    
    return missing

print("üîç Checking system libraries...")
missing_libs = check_system_libraries()
if missing_libs:
    print(f"‚ùå Missing libraries: {missing_libs}")
else:
    print("‚úÖ All required system libraries found")

# LightGBM import with comprehensive diagnostics
LIGHTGBM_AVAILABLE = False
LIGHTGBM_ERROR = None

try:
    # First try to load the shared library directly
    import ctypes
    try:
        ctypes.CDLL('libgomp.so.1')
        print("‚úÖ libgomp.so.1 loaded successfully")
    except OSError as e:
        print(f"‚ùå Failed to load libgomp.so.1: {e}")
        LIGHTGBM_ERROR = f"System library missing: {e}"
    
    # Now try importing LightGBM
    import lightgbm
    LIGHTGBM_AVAILABLE = True
    print("‚úÖ LightGBM imported successfully")
    print(f"üì¶ LightGBM version: {lightgbm.__version__}")
    
except ImportError as e:
    LIGHTGBM_ERROR = f"Import error: {e}"
    print(f"‚ùå LightGBM import failed: {e}")
except Exception as e:
    LIGHTGBM_ERROR = f"Initialization error: {e}"
    print(f"‚ùå LightGBM initialization failed: {e}")

# Define the HybridEnsemble class
class HybridEnsemble:
    def __init__(self, models, weights=None):
        self.models = models
        self.weights = weights
        self.is_fitted = False

    def fit(self, X, y):
        print("  Training individual models for ensemble...")
        for name, model in self.models.items():
            print(f"    Training {name}...")
            if name == 'TabNet':
                model.fit(
                    X, y,
                    max_epochs=100,
                    patience=20,
                    batch_size=128,
                    virtual_batch_size=64
                )
            else:
                model.fit(X, y)
        self.is_fitted = True

    def predict(self, X):
        if not self.is_fitted:
            raise ValueError("Model not fitted yet")

        predictions = []
        prediction_probas = []

        for name, model in self.models.items():
            if name == 'TabNet':
                pred = model.predict(X)
                proba = model.predict_proba(X)
            else:
                pred = model.predict(X)
                proba = model.predict_proba(X)

            if pred.ndim > 1:
                pred = np.argmax(proba, axis=1)

            predictions.append(pred)
            prediction_probas.append(proba)

        predictions = np.array(predictions)
        prediction_probas = np.array(prediction_probas)

        if self.weights is not None:
            weighted_probas = np.average(prediction_probas, axis=0, weights=self.weights)
            final_pred = np.argmax(weighted_probas, axis=1)
        else:
            final_pred = []
            for i in range(predictions.shape[1]):
                votes = predictions[:, i]
                counts = np.bincount(votes)
                final_pred.append(np.argmax(counts))

        return np.array(final_pred)

    def predict_proba(self, X):
        if not self.is_fitted:
            raise ValueError("Model not fitted yet")

        probabilities = []
        for name, model in self.models.items():
            if name == 'TabNet':
                proba = model.predict_proba(X)
            else:
                proba = model.predict_proba(X)
            probabilities.append(proba)

        if self.weights is not None:
            avg_proba = np.average(probabilities, axis=0, weights=self.weights)
        else:
            avg_proba = np.mean(probabilities, axis=0)
        return avg_proba

app = Flask(__name__)
CORS(app)

# Model loading
model_artifacts = None
model_info = None

if LIGHTGBM_AVAILABLE:
    try:
        print("üîÑ Loading model artifacts...")
        artifacts = joblib.load('best_employability_model_60.pkl')
        
        model_artifacts = {
            'model': artifacts['model'],
            'scaler': artifacts.get('scaler'),
            'label_encoder_track': artifacts.get('label_encoder_track'),
            'label_encoder_label': artifacts.get('label_encoder_label'),
            'feature_columns': artifacts.get('feature_columns', [])
        }
        
        # Load model info
        try:
            import json
            with open('model_info_60.json', 'r') as f:
                model_info = json.load(f)
            print("‚úÖ Model info loaded")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not load model info: {e}")
            model_info = None
        
        print("‚úÖ Model artifacts loaded successfully!")
        
    except Exception as e:
        print(f"‚ùå Error loading model artifacts: {e}")
        model_artifacts = None
else:
    print("üö´ LightGBM not available - cannot load model artifacts")

def fallback_prediction(input_data):
    """Enhanced fallback prediction with category weighting"""
    overall_percentage = input_data.get('Overall_Percentage', 0)
    
    # Get all category scores
    categories = {
        'Technical': input_data.get('Technical_Correct', 0),
        'Soft': input_data.get('Soft_Correct', 0),
        'Behavioral': input_data.get('Behavioral_Correct', 0),
        'Career': input_data.get('Career_Correct', 0),
        'Digital': input_data.get('Digital_Correct', 0),
        'Analytical': input_data.get('Analytical_Correct', 0),
        'Creative': input_data.get('Creative_Correct', 0)
    }
    
    # Calculate weighted score (emphasize technical and analytical for employability)
    weights = {
        'Technical': 0.2,
        'Soft': 0.15,
        'Behavioral': 0.15,
        'Career': 0.1,
        'Digital': 0.15,
        'Analytical': 0.2,
        'Creative': 0.05
    }
    
    weighted_score = sum(categories[cat] * weights[cat] for cat in categories)
    
    # Combine with overall percentage
    final_score = (overall_percentage * 0.6) + (weighted_score * 0.4)
    
    # Determine employability level
    if final_score >= 85:
        return "Highly Employable", 0.94
    elif final_score >= 70:
        return "Proficient", 0.89
    elif final_score >= 55:
        return "Competent", 0.84
    elif final_score >= 40:
        return "Emerging", 0.79
    else:
        return "Developing", 0.74

@app.route('/')
def home():
    return jsonify({
        "message": "Employability Prediction API",
        "status": "active",
        "model_loaded": model_artifacts is not None,
        "lightgbm_available": LIGHTGBM_AVAILABLE,
        "lightgbm_error": LIGHTGBM_ERROR,
        "missing_libraries": missing_libs,
        "deployment": "docker-ubuntu"
    })

@app.route('/health')
def health():
    return jsonify({
        "status": "healthy",
        "model_loaded": model_artifacts is not None,
        "lightgbm_available": LIGHTGBM_AVAILABLE,
        "server": "gunicorn"
    })

@app.route('/predict', methods=['POST'])
def predict():
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                "error": "No JSON data received", 
                "status": "error"
            }), 400
        
        # Validate required fields
        required_fields = [
            'Track', 'Technical_Correct', 'Soft_Correct', 'Behavioral_Correct',
            'Career_Correct', 'Digital_Correct', 'Analytical_Correct', 
            'Creative_Correct', 'Overall_Percentage'
        ]
        
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            return jsonify({
                "error": f"Missing fields: {missing_fields}",
                "status": "error"
            }), 400
        
        # Use ML model if available, otherwise use fallback
        if model_artifacts and LIGHTGBM_AVAILABLE:
            try:
                # Your ML prediction logic here
                # For now, use enhanced fallback that mimics ML behavior
                prediction, confidence = fallback_prediction(data)
                model_used = "Enhanced Fallback (ML Compatible)"
                
            except Exception as e:
                print(f"‚ùå ML prediction failed: {e}")
                prediction, confidence = fallback_prediction(data)
                model_used = "Fallback (ML Error)"
        else:
            # Use enhanced fallback prediction
            prediction, confidence = fallback_prediction(data)
            model_used = "Enhanced Fallback System"
        
        response = {
            "prediction": prediction,
            "confidence": confidence,
            "status": "success",
            "model_used": model_used,
            "model_available": model_artifacts is not None and LIGHTGBM_AVAILABLE,
            "lightgbm_working": LIGHTGBM_AVAILABLE
        }
        
        print(f"‚úÖ Prediction: {prediction} (Confidence: {confidence:.2f}) - Model: {model_used}")
        
        return jsonify(response)
        
    except Exception as e:
        print(f"‚ùå Prediction error: {str(e)}")
        prediction, confidence = fallback_prediction(request.get_json() or {})
        return jsonify({
            "prediction": prediction,
            "confidence": confidence,
            "status": "fallback",
            "error": str(e)
        })

# No need for Flask dev server - Gunicorn will run the app
